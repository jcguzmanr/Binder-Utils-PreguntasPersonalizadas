# An√°lisis del Repositorio binder-text-extract y Plan de Desarrollo

## üìã Resumen del An√°lisis

He analizado completamente el repositorio `binder-text-extract` y he identificado los patrones arquitect√≥nicos clave para reutilizar en el nuevo proyecto.

## üèóÔ∏è Arquitectura Identificada

### 1. **Punto de Entrada (lambda_function.py)**
- **Handler principal**: Maneja eventos HTTP y directos
- **Detecci√≥n autom√°tica**: Distingue entre API Gateway y invocaci√≥n directa
- **CORS**: Soporte completo para preflight requests
- **Logging estructurado**: Con contexto de request ID y m√©tricas
- **Manejo de errores**: Robusto con logging de excepciones

### 2. **Configuraci√≥n AWS (aws_clients.py)**
```python
# Patr√≥n identificado:
def make_boto_clients(region: str):
    cfg = Config(
        region_name=region,
        read_timeout=25,
        connect_timeout=5,
        retries={"max_attempts": 3, "mode": "standard"},
        max_pool_connections=10,
    )
    session = boto3.session.Session(region_name=region)
    s3 = session.client("s3", config=cfg)
    textract = session.client("textract", config=cfg)
    lambda_client = session.client("lambda", config=cfg)
    return s3, textract, lambda_client
```

**Elementos clave a reutilizar:**
- Configuraci√≥n de timeouts y reintentos
- Manejo de sesiones boto3
- Retorno de m√∫ltiples clientes AWS

### 3. **Sistema de Configuraci√≥n (config.py)**
```python
@dataclass(frozen=True)
class AppConfig:
    default_bucket: str
    region: str
    allowed_origin: str
    # ... otros campos
```

**Patr√≥n identificado:**
- Uso de dataclasses inmutables
- Configuraci√≥n centralizada con defaults
- Soporte para variables de entorno

### 4. **Arquitectura LLM (carpeta call_llm/)**

#### **Estructura Modular:**
- `api.py`: Punto de entrada principal
- `openai_service.py`: Servicio OpenAI con m√∫ltiples estrategias
- `http.py`: Cliente HTTP personalizado
- `schemas.py`: Definici√≥n de esquemas JSON
- `env.py`: Manejo de variables de entorno
- `prompt.py`: Gesti√≥n de prompts

#### **Patr√≥n de Llamadas OpenAI Identificado:**

1. **Configuraci√≥n Flexible:**
```python
@dataclass
class OpenAIConfig:
    model: str = "gpt-5-nano"
    reasoning_effort: Optional[str] = "low"
    timeout: int = 45
    max_output_tokens: int = 32768
    fallback_model: str = "gpt-4o-mini"
```

2. **M√∫ltiples Estrategias de Fallback:**
   - **Primary**: Responses API con schema JSON estricto
   - **Fallback 1**: Chat completions con JSON strict
   - **Fallback 2**: Chat completions sin formato estricto
   - **Fallback 3**: Modelo alternativo (gpt-4o-mini)

3. **Manejo Robusto de Errores:**
   - Detecci√≥n de errores espec√≠ficos (reasoning no soportado, schema inv√°lido, contexto muy largo)
   - Reintentos autom√°ticos con ajustes
   - Logging detallado de errores

4. **Validaci√≥n y Normalizaci√≥n:**
```python
def normalize_structured_output(data: Any) -> Dict[str, Any]:
    # Normaliza el JSON devuelto por el LLM a la forma esperada
    # Convierte tipos y asegura estructura consistente
```

## üìã An√°lisis del Brief - QA Personalizado

### **Requisitos Identificados:**

1. **Funci√≥n Lambda s√≠ncrona** para procesar preguntas personalizadas sobre contratos
2. **Entrada JSON** con texto del contrato y array de preguntas
3. **Salida estructurada** con respuestas ordenadas y metadatos
4. **Webhook opcional** para notificaciones as√≠ncronas
5. **Validaciones espec√≠ficas** (m√°x. 50 preguntas, 300 chars por pregunta)
6. **Manejo de errores** con c√≥digos espec√≠ficos
7. **Logging y m√©tricas** en CloudWatch

### **Diferencias Clave vs. binder-text-extract:**
- **S√≠ncrono vs. As√≠ncrono**: Este proyecto es s√≠ncrono, el original es as√≠ncrono con worker
- **QA espec√≠fico vs. Extracci√≥n general**: Enfoque en preguntas personalizadas
- **Estructura de salida diferente**: Array de QA vs. JSON estructurado fijo
- **Sin Textract**: No necesita OCR, solo procesamiento de texto

## üéØ Plan de Desarrollo Espec√≠fico

### **Fase 1: Estructura Base del Proyecto QA**
- [ ] Crear estructura de proyecto `binder-qa-personalizado`
- [ ] Implementar `lambda_function.py` adaptado para QA s√≠ncrono
- [ ] Configurar `aws_clients.py` (solo para logging, sin S3/Textract)
- [ ] Crear `config.py` con configuraci√≥n espec√≠fica QA
- [ ] Implementar `qa_service/` con l√≥gica espec√≠fica

### **Fase 2: Adaptaci√≥n del Sistema LLM**
- [ ] Reutilizar carpeta `call_llm/` como base
- [ ] Crear `qa_schemas.py` para validaci√≥n de entrada/salida QA
- [ ] Adaptar `openai_service.py` para procesamiento de preguntas m√∫ltiples
- [ ] Crear `qa_prompt.txt` espec√≠fico para QA sobre contratos
- [ ] Implementar `qa_parser.py` para procesar respuestas estructuradas

### **Fase 3: L√≥gica de Negocio QA**
- [ ] Implementar `qa_controller.py` con flujo s√≠ncrono
- [ ] Crear `qa_validator.py` con validaciones espec√≠ficas
- [ ] Implementar `qa_processor.py` para manejo de m√∫ltiples preguntas
- [ ] Crear `webhook_service.py` para notificaciones opcionales
- [ ] Implementar sistema de confianza y razonamiento

### **Fase 4: Validaciones y Manejo de Errores**
- [ ] Validaci√≥n de entrada (m√°x. 50 preguntas, 300 chars)
- [ ] Validaci√≥n de webhook URL (HTTPS, dominios permitidos)
- [ ] Manejo de timeouts (30-120s)
- [ ] C√≥digos de error espec√≠ficos (BAD_REQUEST, TIMEOUT, MODEL_ERROR, WEBHOOK_ERROR)
- [ ] Sistema de reintentos para webhooks con backoff exponencial

### **Fase 5: Testing y Deployment**
- [ ] Configurar testing local con casos de QA
- [ ] Validar integraci√≥n con OpenAI
- [ ] Configurar API Gateway
- [ ] Configurar CloudWatch logs y m√©tricas
- [ ] Documentaci√≥n y ejemplos de uso

## üîß Componentes a Reutilizar Directamente

### **1. Sistema LLM Completo**
- ‚úÖ **Carpeta `call_llm/` completa** - Arquitectura robusta y probada
- ‚úÖ **M√∫ltiples estrategias de fallback** - Garantiza alta disponibilidad
- ‚úÖ **Manejo de errores espec√≠ficos** - Experiencia probada en producci√≥n

### **2. Configuraci√≥n AWS**
- ‚úÖ **`aws_clients.py`** - Patr√≥n de configuraci√≥n optimizado
- ‚úÖ **Configuraci√≥n de timeouts y reintentos** - Valores probados
- ‚úÖ **Manejo de sesiones boto3** - Mejores pr√°cticas

### **3. Infraestructura HTTP**
- ‚úÖ **`http_gateway.py`** - Soporte completo para API Gateway
- ‚úÖ **Manejo de CORS** - Configuraci√≥n robusta
- ‚úÖ **Parsing de eventos** - Soporte para m√∫ltiples formatos

### **4. Sistema de Logging**
- ‚úÖ **Logging estructurado** - Con contexto y m√©tricas
- ‚úÖ **Manejo de request IDs** - Para trazabilidad
- ‚úÖ **Eventos sem√°nticos** - F√°cil debugging

## üìù Notas Importantes

1. **El repositorio analizado est√° muy bien estructurado** con separaci√≥n clara de responsabilidades
2. **El sistema LLM es especialmente robusto** con m√∫ltiples estrategias de fallback
3. **La configuraci√≥n AWS sigue mejores pr√°cticas** con timeouts y reintentos apropiados
4. **El manejo de errores es exhaustivo** con logging detallado

## üîß Especificaciones T√©cnicas Detalladas

### **Estructura de Archivos Propuesta:**
```
binder-qa-personalizado/
‚îú‚îÄ‚îÄ lambda_function.py
‚îú‚îÄ‚îÄ qa_service/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ controller.py
‚îÇ   ‚îú‚îÄ‚îÄ validator.py
‚îÇ   ‚îú‚îÄ‚îÄ processor.py
‚îÇ   ‚îú‚îÄ‚îÄ webhook_service.py
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py
‚îú‚îÄ‚îÄ call_llm/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ api.py
‚îÇ   ‚îú‚îÄ‚îÄ openai_service.py
‚îÇ   ‚îú‚îÄ‚îÄ qa_schemas.py
‚îÇ   ‚îú‚îÄ‚îÄ qa_parser.py
‚îÇ   ‚îú‚îÄ‚îÄ http.py
‚îÇ   ‚îú‚îÄ‚îÄ env.py
‚îÇ   ‚îî‚îÄ‚îÄ prompt.py
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ aws_clients.py
‚îú‚îÄ‚îÄ http_gateway.py
‚îú‚îÄ‚îÄ logging.py
‚îú‚îÄ‚îÄ utils.py
‚îî‚îÄ‚îÄ qa_prompt.txt
```

### **Adaptaciones Espec√≠ficas del Sistema LLM:**

#### **1. qa_schemas.py** (Nuevo)
```python
def qa_input_schema() -> Dict:
    """Schema para validar entrada de QA"""
    return {
        "type": "object",
        "properties": {
            "texto_contrato": {"type": "string", "minLength": 1},
            "reference_id": {"type": "string", "minLength": 1},
            "qa": {
                "type": "object",
                "properties": {
                    "webhook_url": {"type": "string", "format": "uri"},
                    "incluir_razonamiento": {"type": "boolean"},
                    "preguntas": {
                        "type": "array",
                        "items": {"type": "string", "maxLength": 300},
                        "maxItems": 50,
                        "minItems": 1
                    }
                },
                "required": ["preguntas"]
            }
        },
        "required": ["texto_contrato", "reference_id", "qa"]
    }

def qa_output_schema() -> Dict:
    """Schema para estructura de salida QA"""
    return {
        "type": "object",
        "properties": {
            "success": {"type": "boolean"},
            "reference_id": {"type": "string"},
            "qa_resultados": {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "pregunta_orden": {"type": "integer"},
                        "pregunta": {"type": "string"},
                        "respuesta": {"type": "string"},
                        "confianza": {"type": "number", "minimum": 0, "maximum": 1},
                        "razonamiento": {"type": "string"}
                    }
                }
            },
            "metadatos": {
                "type": "object",
                "properties": {
                    "modelo": {"type": "string"},
                    "latencia_ms": {"type": "integer"},
                    "modo": {"type": "string"},
                    "webhook_disparado": {"type": "boolean"}
                }
            }
        }
    }
```

#### **2. qa_prompt.txt** (Nuevo)
```text
Eres un experto en an√°lisis de contratos y documentos legales.

TAREA: Analizar el contrato proporcionado y responder las preguntas espec√≠ficas de manera precisa y estructurada.

INSTRUCCIONES:
1. Lee cuidadosamente todo el texto del contrato
2. Para cada pregunta, busca la informaci√≥n relevante en el contrato
3. Proporciona respuestas claras y espec√≠ficas
4. Si no encuentras informaci√≥n, responde "No se encontr√≥ informaci√≥n en el contrato"
5. Incluye nivel de confianza (0.0 a 1.0) basado en la claridad de la informaci√≥n
6. Si se solicita razonamiento, explica brevemente d√≥nde encontraste la informaci√≥n

FORMATO DE RESPUESTA:
- Cada respuesta debe ser un objeto JSON con: pregunta_orden, pregunta, respuesta, confianza, razonamiento
- Las respuestas deben mantener el mismo orden que las preguntas de entrada
- Usa confianza alta (0.8-1.0) para informaci√≥n expl√≠cita y clara
- Usa confianza media (0.5-0.7) para informaci√≥n inferida o parcial
- Usa confianza baja (0.1-0.4) para informaci√≥n incierta o ambigua

CONTRATO:
{texto_contrato}

PREGUNTAS:
{preguntas_formateadas}
```

#### **3. qa_processor.py** (Nuevo)
```python
class QAProcessor:
    """Procesador de preguntas y respuestas personalizadas"""
    
    def __init__(self, openai_service, config):
        self.openai_service = openai_service
        self.config = config
    
    def process_questions(self, texto_contrato: str, preguntas: List[str], 
                         incluir_razonamiento: bool = False) -> List[Dict]:
        """Procesa m√∫ltiples preguntas sobre un contrato"""
        # Formatear preguntas para el prompt
        preguntas_formateadas = self._format_questions(preguntas)
        
        # Llamar a OpenAI con prompt espec√≠fico
        respuestas_raw = self.openai_service.run_qa(
            texto_contrato=texto_contrato,
            preguntas=preguntas_formateadas,
            incluir_razonamiento=incluir_razonamiento
        )
        
        # Procesar y normalizar respuestas
        return self._normalize_responses(respuestas_raw, preguntas)
```

### **Configuraci√≥n Espec√≠fica:**

#### **config.py** (Adaptado)
```python
@dataclass(frozen=True)
class QAConfig:
    # L√≠mites de validaci√≥n
    max_preguntas: int = 50
    max_chars_pregunta: int = 300
    min_chars_contrato: int = 100
    
    # Timeouts
    openai_timeout: int = 60
    webhook_timeout: int = 30
    max_total_timeout: int = 120
    
    # OpenAI
    default_model: str = "gpt-4o-mini"
    fallback_model: str = "gpt-3.5-turbo"
    max_output_tokens: int = 4096
    
    # Webhook
    webhook_retry_attempts: int = 3
    webhook_backoff_base: float = 1.5
    
    # AWS
    region: str = "us-east-1"
    log_level: str = "INFO"
```

## üöÄ Pr√≥ximos Pasos

1. **Crear estructura del proyecto** con los archivos identificados
2. **Implementar validaciones** espec√≠ficas del brief
3. **Adaptar sistema LLM** para QA personalizado
4. **Implementar controller** con flujo s√≠ncrono
5. **Configurar webhook service** para notificaciones opcionales

---

*El plan est√° completo y listo para implementaci√≥n. ¬øQuieres que proceda con la creaci√≥n de la estructura del proyecto?*
